{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiago-cortes14/Tesis-Pinos/blob/main/Detectron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsE8lxClMR2O"
      },
      "source": [
        "# 1. Installation of dependencies // Instalación de las dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "betP_k_KIVjX",
        "outputId": "c1c971c0-2816-47a1-b31e-82da702cb28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed correctly!\n"
          ]
        }
      ],
      "source": [
        "# Install Pytorch\n",
        "!pip3 install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip3 install cython pyyaml==5.1\n",
        "!pip3 install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "# Install Detectron2:\n",
        "!pip3 install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
        "\n",
        "# Install tools\n",
        "!pip3 install simplejson\n",
        "!pip3 install progressbar\n",
        "\n",
        "# Pytorch backend \n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "!pip3 install google-cloud-storage\n",
        "\n",
        "# Install Labelbox\n",
        "!pip3 install labelbox\n",
        "!pip install \"labelbox[data]\"\n",
        "\n",
        "# Clear output\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Dependencies installed correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J01g4Nt9fKYT"
      },
      "source": [
        "# 2. Import of libraries // Importación de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbe4YYJrTXSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ad728e-5229-4809-dd24-ac85a1a6b80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported correctly!\n"
          ]
        }
      ],
      "source": [
        "# General \n",
        "import datetime as dt\n",
        "import os, os.path\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "from itertools import cycle\n",
        "from uuid import uuid4\n",
        "import requests\n",
        "from pprint import pprint\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import io\n",
        "import simplejson as json\n",
        "from datetime import datetime\n",
        "import time\n",
        "import shutil\n",
        "from matplotlib import pyplot as plt\n",
        "from pycocotools import mask\n",
        "import progressbar\n",
        "from PIL import Image\n",
        "from google.cloud import storage\n",
        "from google.colab.patches import cv2_imshow\n",
        "import copy\n",
        "import torch\n",
        "\n",
        "# Labelbox \n",
        "import labelbox as lb\n",
        "from labelbox import Project, Dataset,Client, OntologyBuilder\n",
        "from labelbox.schema.bulk_import_request import BulkImportRequest\n",
        "from labelbox.schema.enums import BulkImportRequestState\n",
        "\n",
        "# Detectron2 \n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "\n",
        "clear_output()\n",
        "print(\"Libraries imported correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeP39WxOMpkV"
      },
      "source": [
        "# 3. Parameter declaration // Declaración de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7c5qs1COhy3"
      },
      "outputs": [],
      "source": [
        "# Linking our dataset with labelbox\n",
        "\n",
        "LB_API_KEY ='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3d3aDI3Z2swa3M0MHo5ZzE1eTBiNXlvIiwib3JnYW5pemF0aW9uSWQiOiJja3czenVkOHEwemluMHpiNzh5NTNhdWZtIiwiYXBpS2V5SWQiOiJjbDByZDBwancwZ202MHo2NDdycmFibGkxIiwic2VjcmV0IjoiNmNkY2MyYzQ2ZWRlNTNlY2E2N2EzZjkyZTRiMmQ2NTYiLCJpYXQiOjE2NDczMDE5MDAsImV4cCI6MjI3ODQ1MzkwMH0.B6UY9SMoH9MFcGSWcCyKHdyznuo4IGe39vbH4j6vzyo'\n",
        "PROJECT_ID='ckzm36rbndjk60z781xkcg9an' # Labelbox project id\n",
        "DATASETS=['ckzm39bj003dp0z9d422q9y4s'] # Labelbox dataset ids attached to the project\n",
        "MODE = 'object-detection' \n",
        "DATA_LOCATION = 'obj-data'\n",
        "\n",
        "# Configuration of Detectron2 parameters\n",
        "\n",
        "DOWNLOAD_IMAGES = True  # Download data from labelbox.\n",
        "TRAIN_RATIO = 0.6       # Training data\n",
        "VAL_TEST_RATIO = 0.2    # Validation data / Test data\n",
        "NUM_CPU_THREADS = 8     # For multiprocess downloads\n",
        "NUM_SAMPLE_LABELS = 0 \n",
        "PRELABELING_THRESHOLD = 0.6 # Minimum model inference confidence threshold to be uploaded to labelbox\n",
        "HEADLESS_MODE = False # Set True to skip previewing data or model results\n",
        "\n",
        "DETECTRON_DATASET_TRAINING_NAME = 'prelabeling-train'\n",
        "DETECTRON_DATASET_VALIDATION_NAME = 'prelabeling-val'\n",
        "DETECTRON_DATASET_TEST_NAME = 'prelabeling-test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttsWdnXeMw8O"
      },
      "source": [
        "# 4. Labelbox request // Conexión entre Labelbox y Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI5Q2j0WQAh6"
      },
      "outputs": [],
      "source": [
        "# Get project ontology from labelbox\n",
        "\n",
        "def get_ontology(project_id):\n",
        "    response = client.execute(\n",
        "                \"\"\"\n",
        "                query getOntology (\n",
        "                    $project_id : ID!){ \n",
        "                    project (where: { id: $project_id }) { \n",
        "                        ontology { \n",
        "                            normalized \n",
        "                        } \n",
        "                    }\n",
        "                }\n",
        "                \"\"\",\n",
        "                {\"project_id\": project_id})\n",
        "            \n",
        "    ontology = response['project']['ontology']['normalized']['tools']\n",
        "\n",
        "    # Return list of tools and embed category id to be used to map classname during training and inference\n",
        "    \n",
        "    mapped_ontology = []\n",
        "    thing_classes = []\n",
        "    \n",
        "    i=0\n",
        "    for item in ontology:\n",
        "        item.update({'category': i})\n",
        "        mapped_ontology.append(item)\n",
        "        thing_classes.append(item['name'])\n",
        "        i=i+1\n",
        "\n",
        "    return mapped_ontology, thing_classes\n",
        "\n",
        "# Creates a new export request to get all labels from labelbox. \n",
        "\n",
        "def get_labels(project_id):\n",
        "    should_poll = 1\n",
        "    while(should_poll == 1):\n",
        "        response = client.execute(\n",
        "                    \"\"\"\n",
        "                    mutation export(\n",
        "                    $project_id : ID!    \n",
        "                    )\n",
        "                    { \n",
        "                        exportLabels(data:{ projectId: $project_id }){ \n",
        "                            downloadUrl \n",
        "                            createdAt \n",
        "                            shouldPoll \n",
        "                        }\n",
        "                    }\n",
        "                    \"\"\",\n",
        "                    {\"project_id\": project_id})\n",
        "        \n",
        "        if response['exportLabels']['shouldPoll'] == False:\n",
        "            should_poll = 0\n",
        "            url = response['exportLabels']['downloadUrl']\n",
        "            headers = {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}\n",
        "\n",
        "            r = requests.get(url, headers=headers)\n",
        "            \n",
        "            print('Export generated')\n",
        "            \n",
        "            # Writing export to disc for easier debugging\n",
        "            \n",
        "            open('export.json', 'wb').write(r.content)\n",
        "            return r.content\n",
        "        else:\n",
        "            print('Waiting for export generation. Will check back in 10 seconds.')    \n",
        "            time.sleep(10)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Get all previous predictions import (bulk import request). \n",
        "\n",
        "def get_current_import_requests():\n",
        "    response = client.execute(\n",
        "                    \"\"\"\n",
        "                    query get_all_import_requests(\n",
        "                        $project_id : ID! \n",
        "                    ) {\n",
        "                      bulkImportRequests(where: {projectId: $project_id}) {\n",
        "                        id\n",
        "                        name\n",
        "                      }\n",
        "                    }\n",
        "                    \"\"\",\n",
        "                    {\"project_id\": PROJECT_ID})\n",
        "    \n",
        "    return response['bulkImportRequests']\n",
        "\n",
        "# Delete all current predictions in a project and dataset. We want to delete them and start fresh with predictions from the latest model iteration\n",
        "\n",
        "def delete_import_request(import_request_id):\n",
        "    response = client.execute(\n",
        "                    \"\"\"\n",
        "                        mutation delete_import_request(\n",
        "                            $import_request_id : ID! \n",
        "                        ){\n",
        "                          deleteBulkImportRequest(where: {id: $import_request_id}) {\n",
        "                            id\n",
        "                            name\n",
        "                          }\n",
        "                        }\n",
        "                    \"\"\",\n",
        "                    {\"import_request_id\": import_request_id})\n",
        "    \n",
        "    return response\n",
        "\n",
        "# Function to return the difference between two lists. This is used to compute the queued datarows to be used for inference. \n",
        "\n",
        "def diff_lists(li1, li2): \n",
        "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2] \n",
        "    return li_dif \n",
        "\n",
        "# Generic data download function\n",
        "\n",
        "def download_files(filemap):\n",
        "    path, uri = filemap    \n",
        "    \n",
        "    # Download data\n",
        "    \n",
        "    if not os.path.exists(path):\n",
        "        r = requests.get(uri, stream=True)\n",
        "        if r.status_code == 200:\n",
        "            with open(path, 'wb') as f:\n",
        "                for chunk in r:\n",
        "                    f.write(chunk)\n",
        "    return path\n",
        "\n",
        "#____________________________________________ CONVERT BINARY IMAGE INTO COCO RLE FORMAT_____________________________________________________________________\n",
        "\n",
        "def rle_encode(mask_image):\n",
        "    size = list(mask_image.shape)\n",
        "    pixels = mask_image.flatten()\n",
        "    \n",
        "    pixels[0] = 0\n",
        "    pixels[-1] = 0\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
        "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
        "    \n",
        "    rle = {'counts': runs.tolist(), 'size': size}\n",
        "    return rle\n",
        "\n",
        "def load_set(dir):\n",
        "    with open(dir+\"dataset.json\") as json_file:\n",
        "        dataset_dicts = json.loads(json_file)\n",
        "    return dataset_dicts\n",
        "\n",
        "def cv2_imshow(a, **kwargs):\n",
        "\n",
        "    # Cv2 stores colors as BGR; convert to RGB\n",
        "    \n",
        "    if a.ndim == 3:\n",
        "        if a.shape[2] == 4:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "        else:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return plt.imshow(a, **kwargs)\n",
        "\n",
        "def upload_to_gcs(file_name):\n",
        "    bucket = storage_client.get_bucket(\"predictions-import-test\")\n",
        "    blob = bucket.blob(\"{}.png\".format(str(uuid4())))\n",
        "    blob.upload_from_filename(file_name)\n",
        "    return blob.generate_signed_url(dt.timedelta(weeks=10))\n",
        "\n",
        "def mask_to_cloud(img, mask_array, filename):\n",
        "    num_instances = mask_array.shape[0]\n",
        "    mask_array = np.moveaxis(mask_array, 0, -1)\n",
        "    mask_array_instance = []\n",
        "    output = np.zeros_like(img)\n",
        "    for i in range(num_instances):\n",
        "        mask_array_instance.append(mask_array[:, :, i:(i+1)])\n",
        "        output = np.where(mask_array_instance[i] == True, 255, output)\n",
        "    im = Image.fromarray(output)\n",
        "    im.save(DATA_LOCATION+'tmp/'+filename+'.png')\n",
        "    \n",
        "    cloud_mask = upload_to_gcs(DATA_LOCATION+'tmp/'+filename+'.png')\n",
        "    \n",
        "    return cloud_mask\n",
        "\n",
        "#________________________________________________CONVERT LABELBOX LABELS INTO DETECTRON2 FORMAT___________________________________________________________________\n",
        "\n",
        "def load_detectron2_dataset(labels, ontology, thing_classes, dir):\n",
        "    dataset_dicts = []\n",
        "    i = 0\n",
        "    total = len(labels)\n",
        "\n",
        "    print(\"Num labels processing: \" + str(total))\n",
        "    time.sleep(1)\n",
        "    bar = progressbar.ProgressBar(maxval=total, \\\n",
        "        widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "    bar.start()\n",
        " \n",
        "    # Write detectron2 dataset file to disk for easier debugging\n",
        "\n",
        "    for label in labels:\n",
        "        \n",
        "        try:\n",
        "            record = {}\n",
        "            filename = os.path.join(dir, label['External ID'])\n",
        "            \n",
        "            _ = io.imread(filename)\n",
        "            \n",
        "            height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "            record[\"file_name\"] = filename\n",
        "            record[\"height\"] = height\n",
        "            record[\"width\"] = width\n",
        "            record[\"image_id\"] = label['ID']\n",
        "\n",
        "            objs = []\n",
        "\n",
        "            for instance in label['Label']['objects']:\n",
        "                category_id = thing_classes.index(instance['title'])\n",
        "                \n",
        "                if MODE == 'object-detection':\n",
        "                    obj = {\n",
        "                            \"bbox\": [instance['bbox']['left'], instance['bbox']['top'], instance['bbox']['width'], instance['bbox']['height']],\n",
        "                            \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                            \"segmentation\": [],\n",
        "                            \"category_id\": category_id,\n",
        "                        }\n",
        "                    objs.append(obj)\n",
        "\n",
        "                if MODE == 'segmentation-rle':\n",
        "                    path = DATA_LOCATION+masks+'/'+label['External ID']\n",
        "                    mask_URI = instance['instanceURI']\n",
        "                    downloaded_path = download_files((path, mask_URI))\n",
        "                    im = cv2.imread(downloaded_path,0)\n",
        "\n",
        "                    binary = np.array(im)\n",
        "\n",
        "                    rle = mask.encode(np.asfortranarray(binary))\n",
        "                    ground_truth_bounding_box = mask.toBbox(rle)\n",
        "\n",
        "                    obj = {\n",
        "                            \"bbox\": ground_truth_bounding_box.tolist(),\n",
        "                            \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                            \"segmentation\": rle,\n",
        "                            \"category_id\": category_id,\n",
        "                            \"iscrowd\": 0\n",
        "                        }\n",
        "                    objs.append(obj)\n",
        "\n",
        "            record[\"annotations\"] = objs\n",
        "            dataset_dicts.append(record)\n",
        "            \n",
        "            bar.update(i+1)\n",
        "            i=i+1\n",
        "        except Exception as e:\n",
        "            print('Exception: ', e)\n",
        "\n",
        "    bar.finish()\n",
        "    f = open(dir+\"dataset_dict.json\",\"w\")\n",
        "    f.write(json.dumps(dataset_dicts))\n",
        "    f.close()\n",
        "    \n",
        "    # Write detectron2 dataset file to disk for easier debugging\n",
        "    \n",
        "    return dataset_dicts\n",
        "\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "        if output_folder is None:\n",
        "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "            output_folder = \"coco_eval\"\n",
        "\n",
        "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL93yUfDNwxC"
      },
      "source": [
        "# 5. Declaration of pre-trained model // Declaración del modelo pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCdtzAwLQL5E",
        "outputId": "f7b38de4-7559-46c4-dfe4-cf1776ade65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available classes:  ['Pina']\n",
            "Waiting for export generation. Will check back in 10 seconds.\n",
            "Export generated\n",
            "Downloading training and validation data... \n",
            "\n",
            "Finished downloading training and validation data... \n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "if os.path.exists('coco_eval'):\n",
        "    shutil.rmtree('coco_eval')\n",
        "    \n",
        "client = lb.Client(LB_API_KEY, \"https://api.labelbox.com/graphql\")\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Get labelbox project\n",
        "\n",
        "project = client.get_project(PROJECT_ID)\n",
        "\n",
        "# Get ontology\n",
        "\n",
        "ontology, thing_classes = get_ontology(PROJECT_ID)\n",
        "print('Available classes: ', thing_classes)\n",
        "\n",
        "# Get labels\n",
        "\n",
        "labels = json.loads(get_labels(PROJECT_ID))\n",
        "\n",
        "# Split training and validation labels\n",
        "\n",
        "if NUM_SAMPLE_LABELS !=0:\n",
        "    val_sample = int(VAL_TEST_RATIO*NUM_SAMPLE_LABELS)\n",
        "    val_labels = random.sample(labels, val_sample)\n",
        "    test_sample = int(VAL_TEST_RATIO*NUM_SAMPLE_LABELS)\n",
        "    test_labels = random.sample(labels, test_sample)\n",
        "    train_labels = random.sample(labels, NUM_SAMPLE_LABELS)\n",
        "else:\n",
        "    split = int(VAL_TEST_RATIO*len(labels))\n",
        "    val_labels = labels[:split]\n",
        "    test_labels = labels[split:split*2]\n",
        "    train_labels = labels[split*2:]\n",
        "\n",
        "# Check and create folders for downloading data from Labelbox\n",
        "\n",
        "train = 'train'\n",
        "val = 'val'\n",
        "test='test'\n",
        "\n",
        "inference = 'inference'\n",
        "masks = 'masks'\n",
        "tmp = 'tmp'\n",
        "output = 'out'\n",
        "\n",
        "if not os.path.exists(DATA_LOCATION):\n",
        "    os.makedirs(DATA_LOCATION)\n",
        "\n",
        "if not os.path.exists(DATA_LOCATION+train):\n",
        "    os.makedirs(DATA_LOCATION+train)\n",
        "    \n",
        "if not os.path.exists(DATA_LOCATION+val):\n",
        "    os.makedirs(DATA_LOCATION+val)\n",
        "\n",
        "if not os.path.exists(DATA_LOCATION+test):\n",
        "    os.makedirs(DATA_LOCATION+test)\n",
        "    \n",
        "if not os.path.exists(DATA_LOCATION+tmp):\n",
        "    os.makedirs(DATA_LOCATION+tmp)\n",
        "\n",
        "if not os.path.exists(DATA_LOCATION+output):\n",
        "    os.makedirs(DATA_LOCATION+output)\n",
        "\n",
        "# Download training and validation labels in parallel\n",
        "\n",
        "train_urls = []\n",
        "for label in train_labels:\n",
        "    train_urls.append((DATA_LOCATION+'train/' + label['External ID'], label['Labeled Data']))\n",
        "\n",
        "val_urls = []\n",
        "for label in val_labels:\n",
        "    val_urls.append((DATA_LOCATION+'val/' + label['External ID'], label['Labeled Data']))\n",
        "\n",
        "test_urls = []\n",
        "for label in test_labels:\n",
        "    test_urls.append((DATA_LOCATION+'test/' + label['External ID'], label['Labeled Data']))\n",
        "\n",
        "if(DOWNLOAD_IMAGES==True):\n",
        "    print('Downloading training and validation data... \\n')\n",
        "    \n",
        "    results_train = ThreadPool(NUM_CPU_THREADS).imap_unordered(download_files, train_urls)\n",
        "    results_val = ThreadPool(NUM_CPU_THREADS).imap_unordered(download_files, val_urls)\n",
        "    results_test = ThreadPool(NUM_CPU_THREADS).imap_unordered(download_files, test_urls)\n",
        "\n",
        "    for item in results_train:\n",
        "        pass\n",
        "    for item in results_val:\n",
        "        pass\n",
        "    for item in results_test:\n",
        "        pass\n",
        "    \n",
        "    print('Finished downloading training and validation data... \\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK-sEHFQHkyZ"
      },
      "source": [
        "## Preparing the database for detectron2 // Preparar la base de datos para Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ta05hSxSctO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a6de0b-f28c-46eb-d189-cf57813bab87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num labels processing: 121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load dataset into Detectron2 prelabeling\n",
        "\n",
        "try:\n",
        "    DatasetCatalog.register(DETECTRON_DATASET_TRAINING_NAME, lambda: load_detectron2_dataset(train_labels, ontology, thing_classes, DATA_LOCATION+'train/' ))\n",
        "    DatasetCatalog.register(DETECTRON_DATASET_VALIDATION_NAME, lambda: load_detectron2_dataset(val_labels, ontology, thing_classes, DATA_LOCATION+'val/' ))\n",
        "    DatasetCatalog.register(DETECTRON_DATASET_TEST_NAME, lambda: load_detectron2_dataset(test_labels, ontology, thing_classes, DATA_LOCATION+'test/' ))\n",
        "\n",
        "    MetadataCatalog.get(DETECTRON_DATASET_TRAINING_NAME).thing_classes=thing_classes\n",
        "    MetadataCatalog.get(DETECTRON_DATASET_VALIDATION_NAME).thing_classes=thing_classes\n",
        "    MetadataCatalog.get(DETECTRON_DATASET_TEST_NAME).thing_classes=thing_classes\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "if MODE == 'object-detection':\n",
        "     model = 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml'\n",
        "\n",
        "if MODE == 'segmentation-rle':\n",
        "     model = 'COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'\n",
        "\n",
        "# Load data and metadata for visualization and inference\n",
        "\n",
        "dataset_dicts = DatasetCatalog.get(DETECTRON_DATASET_TRAINING_NAME)\n",
        "dataset_dicts_val = DatasetCatalog.get(DETECTRON_DATASET_VALIDATION_NAME)\n",
        "metadata = MetadataCatalog.get(DETECTRON_DATASET_TRAINING_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyUYq084iC-M"
      },
      "source": [
        "# 6. Train model configs // Configuraciones de entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkLBWUEslWwM"
      },
      "outputs": [],
      "source": [
        "# Train the model. Change the parameters as per your needs. \n",
        "    \n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
        "cfg.DATASETS.TRAIN = (DETECTRON_DATASET_TRAINING_NAME,)\n",
        "cfg.DATASETS.TEST = (DETECTRON_DATASET_VALIDATION_NAME,)   \n",
        "cfg.DATASETS.VAL = (DETECTRON_DATASET_TEST_NAME,)  \n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 150\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "\n",
        "cfg.SOLVER.BASE_LR = 0.00125\n",
        "cfg.SOLVER.MAX_ITER = 1500\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   \n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and validation of model // Entrenamiento y validación del modelo"
      ],
      "metadata": {
        "id": "6FLVxP_ZYgoU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-5jS8tSI1-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9a487d-71d8-4462-94a7-f1abd26a018e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:35:36 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Num labels processing: 121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:35:57 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 121 images left.\n",
            "\u001b[32m[08/24 01:35:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 01:35:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
            "\u001b[32m[08/24 01:35:57 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[08/24 01:35:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:35:58 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[08/24 01:36:37 d2.utils.events]: \u001b[0m eta: 0:47:53  iter: 19  total_loss: 1.238  loss_cls: 0.624  loss_box_reg: 0.259  loss_rpn_cls: 0.308  loss_rpn_loc: 0.039  time: 1.9693  data_time: 0.5744  lr: 0.000025  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:37:17 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 39  total_loss: 0.891  loss_cls: 0.358  loss_box_reg: 0.254  loss_rpn_cls: 0.239  loss_rpn_loc: 0.040  time: 1.9875  data_time: 0.3668  lr: 0.000050  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:37:56 d2.utils.events]: \u001b[0m eta: 0:46:55  iter: 59  total_loss: 0.669  loss_cls: 0.233  loss_box_reg: 0.248  loss_rpn_cls: 0.112  loss_rpn_loc: 0.027  time: 1.9650  data_time: 0.2753  lr: 0.000075  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:38:37 d2.utils.events]: \u001b[0m eta: 0:46:40  iter: 79  total_loss: 0.575  loss_cls: 0.209  loss_box_reg: 0.245  loss_rpn_cls: 0.079  loss_rpn_loc: 0.041  time: 1.9895  data_time: 0.4543  lr: 0.000100  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:39:17 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 99  total_loss: 0.591  loss_cls: 0.209  loss_box_reg: 0.284  loss_rpn_cls: 0.053  loss_rpn_loc: 0.028  time: 1.9900  data_time: 0.2067  lr: 0.000125  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:39:58 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 119  total_loss: 0.572  loss_cls: 0.202  loss_box_reg: 0.287  loss_rpn_cls: 0.059  loss_rpn_loc: 0.031  time: 2.0005  data_time: 0.2487  lr: 0.000150  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:40:38 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 139  total_loss: 0.640  loss_cls: 0.212  loss_box_reg: 0.352  loss_rpn_cls: 0.051  loss_rpn_loc: 0.022  time: 2.0039  data_time: 0.1917  lr: 0.000175  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:41:25 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 01:41:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 01:41:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1421 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 01:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1412 s / img. ETA=0:00:11\n",
            "\u001b[32m[08/24 01:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 32/39. 0.1366 s / img. ETA=0:00:03\n",
            "\u001b[32m[08/24 01:41:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.929978 (0.556764 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:41:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.133185 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:41:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 01:41:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 01:41:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 01:41:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 8.952 | 25.909 | 1.275  | 34.158 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 01:41:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 01:41:52 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 01:41:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 01:41:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 01:41:52 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9519,25.9093,1.2752,34.1584,nan,nan\n",
            "\u001b[32m[08/24 01:42:10 d2.utils.events]: \u001b[0m eta: 0:44:34  iter: 159  total_loss: 0.611  loss_cls: 0.188  loss_box_reg: 0.340  loss_rpn_cls: 0.059  loss_rpn_loc: 0.031  time: 2.0094  data_time: 0.3377  lr: 0.000200  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:42:51 d2.utils.events]: \u001b[0m eta: 0:43:55  iter: 179  total_loss: 0.539  loss_cls: 0.158  loss_box_reg: 0.301  loss_rpn_cls: 0.040  loss_rpn_loc: 0.029  time: 2.0107  data_time: 0.4310  lr: 0.000225  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:43:32 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 199  total_loss: 0.572  loss_cls: 0.151  loss_box_reg: 0.364  loss_rpn_cls: 0.034  loss_rpn_loc: 0.026  time: 2.0173  data_time: 0.2347  lr: 0.000250  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:44:15 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 219  total_loss: 0.554  loss_cls: 0.153  loss_box_reg: 0.333  loss_rpn_cls: 0.026  loss_rpn_loc: 0.025  time: 2.0277  data_time: 0.3287  lr: 0.000275  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:44:56 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 239  total_loss: 0.546  loss_cls: 0.149  loss_box_reg: 0.324  loss_rpn_cls: 0.027  loss_rpn_loc: 0.021  time: 2.0292  data_time: 0.1785  lr: 0.000300  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:45:36 d2.utils.events]: \u001b[0m eta: 0:41:41  iter: 259  total_loss: 0.536  loss_cls: 0.150  loss_box_reg: 0.311  loss_rpn_cls: 0.023  loss_rpn_loc: 0.031  time: 2.0291  data_time: 0.1615  lr: 0.000325  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:46:17 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 279  total_loss: 0.432  loss_cls: 0.130  loss_box_reg: 0.258  loss_rpn_cls: 0.021  loss_rpn_loc: 0.023  time: 2.0295  data_time: 0.3070  lr: 0.000350  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:47:24 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 01:47:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 01:47:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1367 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 01:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1376 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 01:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 31/39. 0.1404 s / img. ETA=0:00:04\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.627443 (0.547866 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.133335 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.471\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 31.687 | 66.004 | 24.169 | 47.129 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 01:47:48 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 01:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: 31.6865,66.0035,24.1691,47.1287,nan,nan\n",
            "\u001b[32m[08/24 01:47:48 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 299  total_loss: 0.398  loss_cls: 0.129  loss_box_reg: 0.238  loss_rpn_cls: 0.021  loss_rpn_loc: 0.028  time: 2.0352  data_time: 0.2484  lr: 0.000375  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:48:28 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 319  total_loss: 0.386  loss_cls: 0.119  loss_box_reg: 0.233  loss_rpn_cls: 0.017  loss_rpn_loc: 0.017  time: 2.0329  data_time: 0.1893  lr: 0.000400  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:49:09 d2.utils.events]: \u001b[0m eta: 0:39:02  iter: 339  total_loss: 0.386  loss_cls: 0.117  loss_box_reg: 0.226  loss_rpn_cls: 0.017  loss_rpn_loc: 0.019  time: 2.0331  data_time: 0.3523  lr: 0.000425  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:49:52 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 359  total_loss: 0.387  loss_cls: 0.119  loss_box_reg: 0.235  loss_rpn_cls: 0.015  loss_rpn_loc: 0.019  time: 2.0406  data_time: 0.4285  lr: 0.000450  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:50:33 d2.utils.events]: \u001b[0m eta: 0:37:49  iter: 379  total_loss: 0.375  loss_cls: 0.111  loss_box_reg: 0.233  loss_rpn_cls: 0.013  loss_rpn_loc: 0.022  time: 2.0408  data_time: 0.1680  lr: 0.000475  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:51:15 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 399  total_loss: 0.370  loss_cls: 0.119  loss_box_reg: 0.226  loss_rpn_cls: 0.011  loss_rpn_loc: 0.018  time: 2.0437  data_time: 0.2342  lr: 0.000500  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:51:58 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 419  total_loss: 0.391  loss_cls: 0.118  loss_box_reg: 0.232  loss_rpn_cls: 0.010  loss_rpn_loc: 0.018  time: 2.0473  data_time: 0.3937  lr: 0.000524  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:52:40 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 439  total_loss: 0.355  loss_cls: 0.093  loss_box_reg: 0.206  loss_rpn_cls: 0.008  loss_rpn_loc: 0.022  time: 2.0496  data_time: 0.2115  lr: 0.000549  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:53:25 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 01:53:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 01:53:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:53:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1277 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 01:53:38 d2.evaluation.evaluator]: \u001b[0mInference done 20/39. 0.1275 s / img. ETA=0:00:09\n",
            "\u001b[32m[08/24 01:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 29/39. 0.1258 s / img. ETA=0:00:05\n",
            "\u001b[32m[08/24 01:53:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.594051 (0.546884 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:53:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.122504 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:53:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 01:53:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 01:53:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.485\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 01:53:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 35.847 | 71.649 | 32.698 | 48.515 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 01:53:50 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 01:53:50 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 01:53:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 01:53:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 01:53:50 d2.evaluation.testing]: \u001b[0mcopypaste: 35.8469,71.6486,32.6984,48.5149,nan,nan\n",
            "\u001b[32m[08/24 01:54:10 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 459  total_loss: 0.352  loss_cls: 0.113  loss_box_reg: 0.223  loss_rpn_cls: 0.010  loss_rpn_loc: 0.016  time: 2.0506  data_time: 0.3707  lr: 0.000574  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:54:50 d2.utils.events]: \u001b[0m eta: 0:34:30  iter: 479  total_loss: 0.343  loss_cls: 0.106  loss_box_reg: 0.200  loss_rpn_cls: 0.009  loss_rpn_loc: 0.018  time: 2.0486  data_time: 0.2829  lr: 0.000599  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:55:31 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 499  total_loss: 0.320  loss_cls: 0.093  loss_box_reg: 0.197  loss_rpn_cls: 0.008  loss_rpn_loc: 0.015  time: 2.0488  data_time: 0.2214  lr: 0.000624  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:56:13 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 519  total_loss: 0.322  loss_cls: 0.090  loss_box_reg: 0.192  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 2.0503  data_time: 0.2477  lr: 0.000649  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:56:54 d2.utils.events]: \u001b[0m eta: 0:32:31  iter: 539  total_loss: 0.297  loss_cls: 0.084  loss_box_reg: 0.184  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 2.0500  data_time: 0.3540  lr: 0.000674  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:57:36 d2.utils.events]: \u001b[0m eta: 0:31:54  iter: 559  total_loss: 0.330  loss_cls: 0.093  loss_box_reg: 0.215  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 2.0520  data_time: 0.3855  lr: 0.000699  max_mem: 8732M\n",
            "\u001b[32m[08/24 01:58:18 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 579  total_loss: 0.299  loss_cls: 0.084  loss_box_reg: 0.192  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 2.0537  data_time: 0.1945  lr: 0.000724  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:59:25 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 01:59:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 01:59:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 01:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1385 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 01:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1322 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 01:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 31/39. 0.1291 s / img. ETA=0:00:04\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.732366 (0.550952 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.127038 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.507\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 37.198 | 72.481 | 36.170 | 50.693 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 01:59:49 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 01:59:49 d2.evaluation.testing]: \u001b[0mcopypaste: 37.1983,72.4814,36.1697,50.6931,nan,nan\n",
            "\u001b[32m[08/24 01:59:49 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 599  total_loss: 0.284  loss_cls: 0.080  loss_box_reg: 0.186  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 2.0541  data_time: 0.2397  lr: 0.000749  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:00:29 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 619  total_loss: 0.297  loss_cls: 0.083  loss_box_reg: 0.198  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0529  data_time: 0.3677  lr: 0.000774  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:01:11 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 639  total_loss: 0.268  loss_cls: 0.070  loss_box_reg: 0.170  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 2.0532  data_time: 0.2744  lr: 0.000799  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:01:53 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 659  total_loss: 0.278  loss_cls: 0.077  loss_box_reg: 0.180  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 2.0557  data_time: 0.3103  lr: 0.000824  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:02:35 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 679  total_loss: 0.272  loss_cls: 0.072  loss_box_reg: 0.184  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 2.0561  data_time: 0.3465  lr: 0.000849  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:03:17 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 699  total_loss: 0.247  loss_cls: 0.070  loss_box_reg: 0.167  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 2.0576  data_time: 0.2589  lr: 0.000874  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:03:59 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 719  total_loss: 0.274  loss_cls: 0.074  loss_box_reg: 0.179  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 2.0593  data_time: 0.1169  lr: 0.000899  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:04:41 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 739  total_loss: 0.241  loss_cls: 0.058  loss_box_reg: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 2.0602  data_time: 0.2844  lr: 0.000924  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:05:27 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 02:05:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 02:05:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:05:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1340 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 02:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1294 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 02:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 30/39. 0.1281 s / img. ETA=0:00:05\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.329414 (0.539100 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.124202 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 36.563 | 72.257 | 34.036 | 48.812 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 02:05:52 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 02:05:52 d2.evaluation.testing]: \u001b[0mcopypaste: 36.5630,72.2571,34.0362,48.8119,nan,nan\n",
            "\u001b[32m[08/24 02:06:11 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 759  total_loss: 0.235  loss_cls: 0.059  loss_box_reg: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 2.0590  data_time: 0.2434  lr: 0.000949  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:06:52 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 779  total_loss: 0.257  loss_cls: 0.064  loss_box_reg: 0.175  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 2.0588  data_time: 0.3407  lr: 0.000974  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:07:33 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 799  total_loss: 0.241  loss_cls: 0.062  loss_box_reg: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 2.0589  data_time: 0.3306  lr: 0.000999  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:08:15 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 819  total_loss: 0.224  loss_cls: 0.057  loss_box_reg: 0.151  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 2.0594  data_time: 0.3188  lr: 0.001024  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:08:57 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 839  total_loss: 0.260  loss_cls: 0.063  loss_box_reg: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 2.0605  data_time: 0.2667  lr: 0.001049  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:09:39 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 859  total_loss: 0.219  loss_cls: 0.057  loss_box_reg: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 2.0617  data_time: 0.2448  lr: 0.001074  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:10:21 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 879  total_loss: 0.205  loss_cls: 0.050  loss_box_reg: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0625  data_time: 0.2205  lr: 0.001099  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:11:28 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 02:11:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 02:11:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1255 s / img. ETA=0:00:11\n",
            "\u001b[32m[08/24 02:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1299 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 02:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 32/39. 0.1297 s / img. ETA=0:00:03\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.374349 (0.540422 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.126778 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.731\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.476\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 37.212 | 73.142 | 32.123 | 47.624 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 02:11:53 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 02:11:53 d2.evaluation.testing]: \u001b[0mcopypaste: 37.2117,73.1425,32.1234,47.6238,nan,nan\n",
            "\u001b[32m[08/24 02:11:53 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 899  total_loss: 0.218  loss_cls: 0.048  loss_box_reg: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 2.0645  data_time: 0.3255  lr: 0.001124  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:12:32 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 919  total_loss: 0.200  loss_cls: 0.050  loss_box_reg: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 2.0624  data_time: 0.1726  lr: 0.001149  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:13:12 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 939  total_loss: 0.197  loss_cls: 0.050  loss_box_reg: 0.135  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 2.0604  data_time: 0.2465  lr: 0.001174  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:13:53 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 959  total_loss: 0.221  loss_cls: 0.052  loss_box_reg: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0603  data_time: 0.2162  lr: 0.001199  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:14:35 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 979  total_loss: 0.207  loss_cls: 0.053  loss_box_reg: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 2.0616  data_time: 0.3270  lr: 0.001224  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:15:18 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 999  total_loss: 0.207  loss_cls: 0.055  loss_box_reg: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0634  data_time: 0.3637  lr: 0.001249  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:15:59 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 1019  total_loss: 0.210  loss_cls: 0.048  loss_box_reg: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0633  data_time: 0.1450  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:16:43 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 1039  total_loss: 0.183  loss_cls: 0.044  loss_box_reg: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0656  data_time: 0.3826  lr: 0.001250  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:17:29 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 02:17:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 02:17:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1340 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 02:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1306 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 02:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 30/39. 0.1298 s / img. ETA=0:00:05\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.383598 (0.540694 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.126246 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.464\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 38.895 | 70.782 | 38.358 | 46.436 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 02:17:53 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 02:17:53 d2.evaluation.testing]: \u001b[0mcopypaste: 38.8949,70.7822,38.3583,46.4356,nan,nan\n",
            "\u001b[32m[08/24 02:18:14 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 1059  total_loss: 0.215  loss_cls: 0.047  loss_box_reg: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0662  data_time: 0.2761  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:18:54 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 1079  total_loss: 0.185  loss_cls: 0.045  loss_box_reg: 0.128  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0656  data_time: 0.2483  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:19:35 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 1099  total_loss: 0.208  loss_cls: 0.049  loss_box_reg: 0.143  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 2.0648  data_time: 0.2764  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:20:16 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 1119  total_loss: 0.181  loss_cls: 0.041  loss_box_reg: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 2.0652  data_time: 0.2021  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:20:59 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 1139  total_loss: 0.178  loss_cls: 0.041  loss_box_reg: 0.125  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0659  data_time: 0.2663  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:21:41 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 1159  total_loss: 0.170  loss_cls: 0.038  loss_box_reg: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 2.0667  data_time: 0.3157  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:22:22 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1179  total_loss: 0.180  loss_cls: 0.041  loss_box_reg: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0668  data_time: 0.2130  lr: 0.001250  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:23:29 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 02:23:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 02:23:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1442 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 02:23:44 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1336 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 02:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 31/39. 0.1320 s / img. ETA=0:00:04\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.420289 (0.541773 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.128178 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.463\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.224\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 39.339 | 72.085 | 39.269 | 46.337 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 02:23:53 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 02:23:53 d2.evaluation.testing]: \u001b[0mcopypaste: 39.3388,72.0854,39.2692,46.3366,nan,nan\n",
            "\u001b[32m[08/24 02:23:53 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 1199  total_loss: 0.177  loss_cls: 0.042  loss_box_reg: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 2.0674  data_time: 0.2876  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:24:33 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 1219  total_loss: 0.185  loss_cls: 0.044  loss_box_reg: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 2.0658  data_time: 0.4823  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:25:13 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1239  total_loss: 0.178  loss_cls: 0.039  loss_box_reg: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 2.0652  data_time: 0.2276  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:25:56 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 1259  total_loss: 0.192  loss_cls: 0.043  loss_box_reg: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0658  data_time: 0.4196  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:26:36 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 1279  total_loss: 0.170  loss_cls: 0.036  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0655  data_time: 0.1698  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:27:19 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 1299  total_loss: 0.177  loss_cls: 0.038  loss_box_reg: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 2.0666  data_time: 0.2906  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:28:01 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1319  total_loss: 0.146  loss_cls: 0.031  loss_box_reg: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 2.0670  data_time: 0.1871  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:28:43 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1339  total_loss: 0.170  loss_cls: 0.039  loss_box_reg: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 2.0677  data_time: 0.1129  lr: 0.001250  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:29:29 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 02:29:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 02:29:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1277 s / img. ETA=0:00:11\n",
            "\u001b[32m[08/24 02:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1344 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 02:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 29/39. 0.1424 s / img. ETA=0:00:06\n",
            "\u001b[32m[08/24 02:29:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.677095 (0.578738 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:29:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.134896 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:29:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 02:29:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 02:29:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 02:29:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 39.676 | 72.500 | 38.010 | 48.218 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 02:29:55 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 02:29:55 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 02:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 02:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 02:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: 39.6756,72.5000,38.0100,48.2178,nan,nan\n",
            "\u001b[32m[08/24 02:30:14 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1359  total_loss: 0.180  loss_cls: 0.042  loss_box_reg: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0676  data_time: 0.3826  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:30:55 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 1379  total_loss: 0.172  loss_cls: 0.038  loss_box_reg: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 2.0673  data_time: 0.3320  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:31:36 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 1399  total_loss: 0.162  loss_cls: 0.036  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 2.0669  data_time: 0.1892  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:32:19 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 1419  total_loss: 0.158  loss_cls: 0.035  loss_box_reg: 0.112  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 2.0680  data_time: 0.3310  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:33:01 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1439  total_loss: 0.154  loss_cls: 0.035  loss_box_reg: 0.109  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 2.0686  data_time: 0.4531  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:33:43 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 1459  total_loss: 0.150  loss_cls: 0.037  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 2.0687  data_time: 0.1276  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:34:24 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 1479  total_loss: 0.161  loss_cls: 0.040  loss_box_reg: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 2.0689  data_time: 0.2836  lr: 0.001250  max_mem: 8732M\n",
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:35:33 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/24 02:35:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[08/24 02:35:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 39 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/24 02:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/39. 0.1418 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/24 02:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 21/39. 0.1349 s / img. ETA=0:00:10\n",
            "\u001b[32m[08/24 02:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 31/39. 0.1307 s / img. ETA=0:00:04\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.311493 (0.538573 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.126619 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.480\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
            "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
            "| 39.933 | 74.197 | 37.275 | 48.020 |  nan  |  nan  |\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[08/24 02:35:57 d2.engine.defaults]: \u001b[0mEvaluation results for prelabeling-val in csv format:\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[08/24 02:35:57 d2.evaluation.testing]: \u001b[0mcopypaste: 39.9325,74.1968,37.2753,48.0198,nan,nan\n",
            "\u001b[32m[08/24 02:35:57 d2.utils.events]: \u001b[0m eta: 0:00:02  iter: 1499  total_loss: 0.137  loss_cls: 0.033  loss_box_reg: 0.096  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 2.0693  data_time: 0.2037  lr: 0.001250  max_mem: 8732M\n",
            "\u001b[32m[08/24 02:35:57 d2.engine.hooks]: \u001b[0mOverall training speed: 1497 iterations in 0:51:39 (2.0707 s / it)\n",
            "\u001b[32m[08/24 02:35:57 d2.engine.hooks]: \u001b[0mTotal training time: 0:59:55 (0:08:15 on hooks)\n"
          ]
        }
      ],
      "source": [
        "if MODE=='segmentation-rle':\n",
        "    cfg.INPUT.MASK_FORMAT='bitmask'\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CocoTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gkNxzV4mEtT"
      },
      "source": [
        "# 7. Creation of our Detectron2 model // Creación de nuestro modelo del Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqcq7faFdoLv"
      },
      "outputs": [],
      "source": [
        "# Set newly trained model for inference. Make sure to set the appropriate threshold. \n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = PRELABELING_THRESHOLD  # set threshold for this model\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "\n",
        "# Create predictor\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHzIm1CPmLF5"
      },
      "source": [
        "# 8. Preview inferences // Pre-visualización de inferencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMLTH062iSvq",
        "outputId": "9c29a7c4-db41-4551-a429-9531989504a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num labels processing: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        " dataset_dicts_test = DatasetCatalog.get(DETECTRON_DATASET_TEST_NAME)\n",
        "\n",
        "if HEADLESS_MODE==False:\n",
        "    for d in random.sample(dataset_dicts_test, len(dataset_dicts_test)):    \n",
        "            im = cv2.imread(d[\"file_name\"])\n",
        "            outputs = predictor(im)\n",
        "            categories = outputs[\"instances\"].to(\"cpu\").pred_classes.numpy()\n",
        "            predicted_boxes = outputs[\"instances\"].to(\"cpu\").pred_boxes\n",
        "            \n",
        "            if MODE=='segmentation-rle':\n",
        "                pred_masks = outputs[\"instances\"].to(\"cpu\").pred_masks.numpy()\n",
        "\n",
        "            if len(categories) != 0:\n",
        "                for i in range(len(categories)):\n",
        "                    classname = thing_classes[categories[i]]\n",
        "                    for item in ontology:\n",
        "                        if classname==item['name']:\n",
        "                            schema_id = item['featureSchemaId']\n",
        "\n",
        "            v = Visualizer(im[:, :, ::-1],\n",
        "                        metadata=metadata, \n",
        "                        #instance_mode=ColorMode.IMAGE_BW,\n",
        "                        scale=2,\n",
        "            )\n",
        "            v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "          \n",
        "            plt.rcParams['figure.figsize'] = (24, 48)\n",
        "            plt.imsave(os.path.join('/content/obj-dataout/', d[\"file_name\"][13:]),v.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT5EuhzjSS96"
      },
      "source": [
        "# 9. Results // Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ9YaMVy4AGi"
      },
      "outputs": [],
      "source": [
        "from torch import distributed\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"prelabeling-test\",cfg,distributed, output_dir=\"./obj-datatest\")\n",
        "val_loader = build_detection_test_loader(cfg, \"prelabeling-test\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display of results on Tensorboard // Visualización de los resultados en Tensorboard"
      ],
      "metadata": {
        "id": "L5KCiEijaG9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ZPEziJ7g4I"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHX3QQn44R9l"
      },
      "source": [
        "\n",
        "# 10. References // Referencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkkNmeaQ4NMK"
      },
      "outputs": [],
      "source": [
        "# @misc{wu2019detectron2,\n",
        "#   author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and\n",
        "#                   Wan-Yen Lo and Ross Girshick},\n",
        "#   title =        {Detectron2},\n",
        "#   howpublished = {\\url{https://github.com/facebookresearch/detectron2}},\n",
        "#   year =         {2019}\n",
        "# }"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eeP39WxOMpkV"
      ],
      "machine_shape": "hm",
      "name": "Detectron2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
